<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Yann&#39;s Pages</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://zhaoyanpeng.cn/"/>
  <updated>2017-06-21T12:30:18.000Z</updated>
  <id>http://zhaoyanpeng.cn/</id>
  
  <author>
    <name>Yanpeng Zhao</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>CYK with Unary Rules</title>
    <link href="http://zhaoyanpeng.cn/2018/12/08/CYK-with-Unary-Rules/"/>
    <id>http://zhaoyanpeng.cn/2018/12/08/CYK-with-Unary-Rules/</id>
    <published>2018-12-08T09:10:50.000Z</published>
    <updated>2017-06-21T12:30:18.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Grammar-Rules"><a href="#Grammar-Rules" class="headerlink" title="Grammar Rules"></a>Grammar Rules</h1><p>$S$ or $R$ is used as the root node in the following discussion, so $O(S)=O(R)=1$.</p><table><thead><tr><th style="text-align:center">Binary Rules (w)</th><th style="text-align:center">Unary Rules (w)</th><th style="text-align:center">Lexicons (w)</th><th style="text-align:center">Possible Chain Rules</th></tr></thead><tbody><tr><td style="text-align:center"><code>D-&gt;BC</code> (2)<br><code>E-&gt;BC</code> (3)<br><code>F-&gt;BC</code> (4)<br><code>S-&gt;AD</code> (2)<br><code>S-&gt;AE</code> (3)<br><code>S-&gt;AF</code> (3)<br><code>S-&gt;AG</code> (2)</td><td style="text-align:center"><code>F-&gt;E</code> (2)<br><code>E-&gt;D</code> (3)<br><code>G-&gt;E</code> (3)</td><td style="text-align:center"><code>A-&gt;w0</code> (2)<br><code>B-&gt;w1</code> (2)<br><code>C-&gt;w2</code> (1)</td><td style="text-align:center"><code>null</code><br><code>F-&gt;E</code><br><code>G-&gt;E</code><br><code>E-&gt;D</code><br><code>F-&gt;E-&gt;D</code><br><code>G-&gt;E-&gt;D</code></td></tr></tbody></table><a id="more"></a><p>When you draw out all the possible parse trees spanning the sentence <code>w0,w1,w2</code>, you could find the only difference among these parse trees is about the choices of chain rules. We only consider chain unary rules of length less than or equal to 2 in weighted context free grammar, and define 3 levels for inside scores and outside scores of nonterminals involved in such chains. Level index that ranges from 0 to 2 increases from the bottom up (top down) for inside scores (outside scores). Each level <code>L</code> contains nonterminals that are exactly the upmost (bottommost) ones in the chain unary rules of length <code>L</code> for inside scores (outside scores).</p><h1 id="Inside-Scores-amp-Outside-Scores"><a href="#Inside-Scores-amp-Outside-Scores" class="headerlink" title="Inside Scores &amp; Outside Scores"></a>Inside Scores &amp; Outside Scores</h1><table><thead><tr><th style="text-align:center">Levels</th><th style="text-align:center">Inside Scores (w)</th><th style="text-align:center">Outside Scores</th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center"><code>I0(D) = w(D-&gt;BC)I(B)I(C)=4</code><br><code>I0(E) = w(E-&gt;BC)I(B)I(C)=6</code><br><code>I0(F) = w(F-&gt;BC)I(B)I(C)=8</code></td><td style="text-align:center"><code>O0(D) = I(A)w(S-&gt;AD)O(S)=4</code><br><code>O0(E) = I(A)w(S-&gt;AE)O(S)=6</code><br><code>O0(F) = I(A)w(S-&gt;AF)O(S)=6</code><br><code>O0(G) = I(A)w(S-&gt;AG)O(S)=4</code></td></tr><tr><td style="text-align:center">1</td><td style="text-align:center"><code>I1(E) = w(E-&gt;D)I0(D)=12</code><br><code>I1(F) = w(F-&gt;E)I0(E)=12</code><br><code>I1(G) = w(G-&gt;E)I0(E)=18</code></td><td style="text-align:center"><code>O1(D) = w(E-&gt;D)O0(E)=18</code><br><code>O1(E) = w(F-&gt;E)O0(F) + w(G-&gt;E)O0(G)=24</code></td></tr><tr><td style="text-align:center">2</td><td style="text-align:center"><code>I2(F) = w(F-&gt;E)I1(E)=24</code><br><code>I2(G) = w(G-&gt;E)I1(E)=36</code></td><td style="text-align:center"><code>O2(D) = w(E-&gt;D)O1(E)=72</code></td></tr></tbody></table><p>From inside scores in the chain unary rules in the above table, we can compute the score of the sentence $w_{0}w_{1}w_{2}$ as</p>\begin{align}I(S) = I(A)\sum_{X \in \mathbf{X}} w(S \rightarrow AX)\sum_{i = 0, 1, 2} I_{i}(X),\end{align}<p>where $S$ is the root node, $\mathbf{X}$ is the nonterminal set, $ w(S \rightarrow AX) = I_{i}(X) = 0 $ if such rules or inside scores do not exist. And</p>\begin{align*}I(S) &= 2 \cdot ((4 \times 2 + 6 \times 3 + 8 \times 3) \\&+ (12 \times 3 + 12 \times 3 + 18 \times 2) + (24 \times 3 + 36 \times 2)) \\&= ((16 + 36 + 46) + (72 + 72 + 72) + (144 + 144))\end{align*}<h2 id="Additional-Grammar-Rules"><a href="#Additional-Grammar-Rules" class="headerlink" title="Additional Grammar Rules"></a>Additional Grammar Rules</h2><p>We introduce a constant M to represent the weight of the partial parse trees that dominate $ w_{2}w_{3} $ and replace $S$ with $J, K, L$. Also we add the additional grammar rules presented in the following table. The chain unary rules starting with $R$ are not included in possible chain rules.</p><table><thead><tr><th style="text-align:center">Binary Rules (w)</th><th style="text-align:center">Unary Rules (w)</th><th style="text-align:center">Lexicons (w)</th><th style="text-align:center">Possible Chain Rules</th></tr></thead><tbody><tr><td style="text-align:center"><code>J-&gt;AM</code> (2)<br> <code>K-&gt;AM</code> (1)<br> <code>L-&gt;AM</code> (3)</td><td style="text-align:center"><code>K-&gt;J</code> (2)<br><code>L-&gt;K</code> (3)<br><code>R-&gt;J</code> (3)<br> <code>R-&gt;K</code> (2)<br> <code>R-&gt;L</code> (1)</td><td style="text-align:center"></td><td style="text-align:center"><code>null</code><br><code>K-&gt;J</code><br><code>L-&gt;K</code><br><code>L-&gt;K-&gt;J</code></td></tr></tbody></table><table><thead><tr><th style="text-align:center">Levels</th><th style="text-align:center">Inside Scores (w)</th><th style="text-align:center">Outside Scores</th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center"><code>I0(J) = w(J-&gt;AM)I(A)I(M)=4M</code><br><code>I0(K) = w(K-&gt;AM)I(A)I(M)=2M</code><br><code>I0(L) = w(L-&gt;AM)I(A)I(M)=6M</code></td><td style="text-align:center"><code>O0(J) = w(R-&gt;J)O(R)=3</code><br><code>O0(K) = w(R-&gt;K)O(R)=2</code><br><code>O0(L) = w(R-&gt;L)O(R)=1</code></td></tr><tr><td style="text-align:center">1</td><td style="text-align:center"><code>I1(K) = w(K-&gt;J)I0(J)=8M</code><br><code>I1(L) = w(L-&gt;K)I0(K)=6M</code></td><td style="text-align:center"><code>O1(J) = w(K-&gt;J)O0(K)=4</code><br><code>O1(K) = w(L-&gt;K)O0(L)=3</code></td></tr><tr><td style="text-align:center">2</td><td style="text-align:center"><code>I2(L) = w(L-&gt;K)I1(K)=24M</code></td><td style="text-align:center"><code>O2(J) = w(K-&gt;J)O1(K)=6</code></td></tr></tbody></table>\begin{align*}I(R) &= ((3 \times 4M + 2 \times 2M + 1 \times 6M) + (2 \times 8M + 1 \times 6M) + (1 \times 24M)) \\&= ((12M + 4M + 6M) + (16M + 6M) + (24M))\end{align*}<h2 id="Counts-of-Binary-Rule-c-S-rightarrow-AX"><a href="#Counts-of-Binary-Rule-c-S-rightarrow-AX" class="headerlink" title="Counts of Binary Rule $c(S \rightarrow AX)$"></a>Counts of Binary Rule $c(S \rightarrow AX)$</h2><p>For any nonterminal $X$, we need to find all its occurances in three levels. When $X = D$,</p>\begin{align*}c(S \rightarrow AD) &= I(A) O(S) w(S \rightarrow AD) I(D) \\&= I(A) w(S \rightarrow AD) \sum_{j = 0, 1, 2}O_{j}(S)  \sum_{i = 0, 1, 2} I_{i}(D) \\\end{align*}\begin{align*}c(J \rightarrow AM) &= w(R \rightarrow J)w(J \rightarrow AM)w(A \rightarrow w_{1})M \\&+  w(R \rightarrow K)w(K \rightarrow J)w(J \rightarrow AM)w(A \rightarrow w_{1})M \\&+ w(R \rightarrow L)w(L \rightarrow K)w(K \rightarrow J)w(J \rightarrow AM)w(A \rightarrow w_{1})M \\&= 12M + 16M + 24M = 52M \\&= \color{red}{ I(A)w(J \rightarrow AM)O(J)M} \\&= \color{red}{ I(A)w(J \rightarrow AM)\sum_{i = 0,1,2}O_{i}(J)M} \\&= 2 \times 2 \times (3 + 4 + 6)M = 52M\end{align*}<h2 id="Counts-of-Unary-Rule-c-X-rightarrow-Y"><a href="#Counts-of-Unary-Rule-c-X-rightarrow-Y" class="headerlink" title="Counts of Unary Rule $c(X \rightarrow Y)$"></a>Counts of Unary Rule $c(X \rightarrow Y)$</h2>\begin{align*}c(X \rightarrow Y) &= \{c(X \rightarrow Y) | X \rightarrow Y \text{ is the chain rule of length 1}\} \\&+ \{\sum_{Z \in \mathbf{X}} c(X \rightarrow Y \rightarrow Z) + c(Z \rightarrow X \rightarrow Y) | X \rightarrow Y \text{ is involved in the chain rule of length 2}\} \\&= w(X \rightarrow Y)(O_{0}(X)I_{0}(Y) + O_{0}(X)I_{1}(Y) + O_{1}(X)I_{0}(D))\end{align*}<p>Let $X = E, Y = D$, we can verify the above formula.</p><p>The score of all the parse trees containing the unary rule $E \rightarrow D$ is</p>\begin{align*}c(E \rightarrow D) &= \sum_{T \sim w_{0}w_{1}w_{2} \text{ and } E \rightarrow D \in T} w(T) \\&= w(A \rightarrow w_{0}) w(S \rightarrow AE) w(E \rightarrow D) w(D \rightarrow BC) w(B \rightarrow w_{1}) w(C \rightarrow w_{2}) \\&+ w(A \rightarrow w_{0}) w(S \rightarrow AE) w(F \rightarrow E) w(E \rightarrow D) w(D \rightarrow BC) w(B \rightarrow w_{1}) w(C \rightarrow w_{2}) \\&+ w(A \rightarrow w_{0}) w(S \rightarrow AE) w(G \rightarrow E) w(E \rightarrow D) w(D \rightarrow BC) w(B \rightarrow w_{1}) w(C \rightarrow w_{2}) \\&= 2 \times 3 \times 3 \times 2 \times 2 \times 1 \\&+ 2 \times 3 \times 2 \times 3 \times 2 \times 2 \times 1 \\&+ 2 \times 2 \times 3 \times 3 \times 2 \times 2 \times 1 \\&= 72 + 144 + 144 \\&= \color{red}{w(E \rightarrow D)(O_{0}(E)I_{0}(D) + O_{1}(E)I_{0}(D))} \\&= 3 \times (6 \times 4 + 24 \times 4) \\&= 72 + 288\end{align*}]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Grammar-Rules&quot;&gt;&lt;a href=&quot;#Grammar-Rules&quot; class=&quot;headerlink&quot; title=&quot;Grammar Rules&quot;&gt;&lt;/a&gt;Grammar Rules&lt;/h1&gt;&lt;p&gt;$S$ or $R$ is used as the root node in the following discussion, so $O(S)=O(R)=1$.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Binary Rules (w)&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Unary Rules (w)&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Lexicons (w)&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Possible Chain Rules&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;&lt;code&gt;D-&amp;gt;BC&lt;/code&gt; (2)&lt;br&gt;&lt;code&gt;E-&amp;gt;BC&lt;/code&gt; (3)&lt;br&gt;&lt;code&gt;F-&amp;gt;BC&lt;/code&gt; (4)&lt;br&gt;&lt;code&gt;S-&amp;gt;AD&lt;/code&gt; (2)&lt;br&gt;&lt;code&gt;S-&amp;gt;AE&lt;/code&gt; (3)&lt;br&gt;&lt;code&gt;S-&amp;gt;AF&lt;/code&gt; (3)&lt;br&gt;&lt;code&gt;S-&amp;gt;AG&lt;/code&gt; (2)&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;&lt;code&gt;F-&amp;gt;E&lt;/code&gt; (2)&lt;br&gt;&lt;code&gt;E-&amp;gt;D&lt;/code&gt; (3)&lt;br&gt;&lt;code&gt;G-&amp;gt;E&lt;/code&gt; (3)&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;&lt;code&gt;A-&amp;gt;w0&lt;/code&gt; (2)&lt;br&gt;&lt;code&gt;B-&amp;gt;w1&lt;/code&gt; (2)&lt;br&gt;&lt;code&gt;C-&amp;gt;w2&lt;/code&gt; (1)&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;&lt;code&gt;null&lt;/code&gt;&lt;br&gt;&lt;code&gt;F-&amp;gt;E&lt;/code&gt;&lt;br&gt;&lt;code&gt;G-&amp;gt;E&lt;/code&gt;&lt;br&gt;&lt;code&gt;E-&amp;gt;D&lt;/code&gt;&lt;br&gt;&lt;code&gt;F-&amp;gt;E-&amp;gt;D&lt;/code&gt;&lt;br&gt;&lt;code&gt;G-&amp;gt;E-&amp;gt;D&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
    
    </summary>
    
      <category term="Parsing" scheme="http://zhaoyanpeng.cn/categories/Parsing/"/>
    
    
      <category term="CYK" scheme="http://zhaoyanpeng.cn/tags/CYK/"/>
    
      <category term="Toy Grammars" scheme="http://zhaoyanpeng.cn/tags/Toy-Grammars/"/>
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://zhaoyanpeng.cn/2017/06/17/Index/"/>
    <id>http://zhaoyanpeng.cn/2017/06/17/Index/</id>
    <published>2017-06-17T18:04:41.000Z</published>
    <updated>2020-11-28T21:26:02.946Z</updated>
    
    <content type="html"><![CDATA[<div style="display: flex;flex-wrap: wrap;font-family: 'Times New Roman';font-size: 14px;padding: 0;margin: -30px 0 30px 0"><div style="max-width: 35%;min-width: 180px;padding: 0 0 0 1px;margin: 0 30px 0 0;position: relative;text-align: left;"><img src="/images/yan.png" alt="Yanpeng Zhao (赵彦鹏)" width="100%" height=""></div><div style="max-width: 60%;min-width: 270px;padding: 0 0 0 1px;position: relative;text-align: left;"><h1 style="font-size:200%;line-height:auto;margin: 0 0 10px 0;">Yanpeng Zhao <span style="display: none !important;font-family:Baskerville; font-size:90%">(Yann)</span></h1><p style="font-size:120%;line-height: 1.2;margin: 0;padding: 0;"><br> <span><b>The University of Edinburgh</b></span><br><br><br><span>My research interest is in structured prediction and latent variable models. Check out my <a href="https://scholar.google.com/citations?hl=en&amp;user=-T9FigIAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" target="_blank" rel="noopener">recent work</a> or <a href="mailto:yanp.zhao@ed.ac.uk" target="_blank" rel="noopener">email me</a>.<br><span style=""><!-- <span><b>Email</b>: <tt>zhaoyp1#shanghaitech$\cdot$edu$\cdot$cn</tt></span><br><br><span style=""> --><!-- [[Publication](#Publications)] [[Education](#Education)] [[Experience](#Experience)] [[Awards](#Selected-Awards)] [[Resume](/files/cv_zhao.pdf)] --></span></span></p></div></div><p style="font-family: 'Times New Roman';line-height: 1.5;">I am a Ph.D. student in the <a href="http://web.inf.ed.ac.uk/ilcc" target="_blank" rel="noopener">ILCC</a> at the <a href="https://www.ed.ac.uk/" target="_blank" rel="noopener">University of Edinburgh</a>, under the supervision of Prof. <a href="http://ivan-titov.org/" target="_blank" rel="noopener">Ivan Titov</a> and <a href="http://homepages.inf.ed.ac.uk/mlap/" target="_blank" rel="noopener">Mirella Lapata</a>. I am also a member of the <a href="http://edinburghnlp.inf.ed.ac.uk/" target="_blank" rel="noopener">Edinburgh NLP</a>. Before moving to Edinburgh, I spent three wonderful years in the <a href="https://sist.shanghaitech.edu.cn/sist_en/" target="_blank" rel="noopener">SIST</a> at <a href="https://www.shanghaitech.edu.cn/eng/" target="_blank" rel="noopener">ShanghaiTech University</a> and worked with Prof. <a href="http://faculty.sist.shanghaitech.edu.cn/faculty/tukw/" target="_blank" rel="noopener">Kewei Tu</a>.</p><!-- <p style="font-family: 'Times New Roman';line-height: 1.5;">Hi! I am a third-year M.Sc. student in the [School of Information Science and Technology](http://sist.shanghaitech.edu.cn/) at [ShanghaiTech University](http://shanghaitech.edu.cn/), under the supervision of Prof. [Kewei Tu](http://sist.shanghaitech.edu.cn/faculty/tukw/). --><!-- My research interests are in natural language processing (NLP) and machine learning (ML), with a focus on machine learning approaches to linguistic structure prediction and language understanding and generation. --><!-- <b>I will graduate in June, and I am looking for a research assistant job. Drop me an email if you are interested in my background and experience.</b></p> --><!--## Current Work<p style="font-family: 'Times New Roman';line-height: 1.5;">I'm studying constituency parsing with latent variables. We propose Latent Vector Grammars (LVeGs), a new constituency parsing framework, which models nonterminal subtypes in a high dimensional continuous space.</p>--><h2 id="News"><a href="#News" class="headerlink" title="News"></a>News</h2><ul><li>First EMNLP <a href="https://arxiv.org/abs/2009.12404" target="_blank" rel="noopener">paper</a> received review scores (4.5/5, 4.5/5, 4.5/5)<br><em>“A clear step forward with novel methods and strong improvement.”</em> – Anonymous Reviews</li><li>First ACL <a href="https://arxiv.org/abs/1805.04688" target="_blank" rel="noopener">paper</a> received review scores (6/6, 5/6, 5/6)<br><em>“The first general framework of using latent vectors for grammars.”</em> – Anonymous Reviews</li></ul><h2 id="Publications"><a href="#Publications" class="headerlink" title="Publications"></a>Publications</h2><ul><li><a href="https://arxiv.org/abs/2009.12404" target="_blank" rel="noopener">Visually Grounded Compound PCFGs</a><br><strong>Yanpeng Zhao</strong> and Ivan Titov.<br>EMNLP 2020 (<a href="https://2020.emnlp.org/blog/2020-11-19-best-papers" target="_blank" rel="noopener"><strong>Best Paper Honorable Mention</strong></a>). [<a href="https://arxiv.org/abs/2009.12404" target="_blank" rel="noopener">paper</a>], [<a href="https://github.com/zhaoyanpeng/vpcfg" target="_blank" rel="noopener">code</a>], [<a href="/files/emnlp2020_reviews.txt">reviews</a>].</li></ul><p style="margin-top: 0;margin-bottom: 5px;"><strong><em>Preprints</em></strong></p><ul><li><a href="/files/An%20Empirical%20Study%20of%20Compound%20PCFGs.pdf">An Empirical Study of Compound PCFGs</a><br><strong>Yanpeng Zhao</strong>.<br>Preprint 2020. [<a href="/files/An%20Empirical%20Study%20of%20Compound%20PCFGs.pdf">paper</a>], [<a href="https://github.com/zhaoyanpeng/cpcfg" target="_blank" rel="noopener">code</a>].</li><li><a href="https://arxiv.org/abs/2005.00278v2" target="_blank" rel="noopener">Unsupervised Transfer of Semantic Role Models from Verbal to Nominal Domain</a><br><strong>Yanpeng Zhao</strong> and Ivan Titov.<br>Preprint 2020. [<a href="https://arxiv.org/abs/2005.00278v2" target="_blank" rel="noopener">paper</a>], [<a href="https://github.com/zhaoyanpeng/srltransfer" target="_blank" rel="noopener">code</a>].</li></ul><p style="margin-top: 0;margin-bottom: 5px;"><strong><em>Before 2018</em></strong></p><!-- <p style="margin-top: 0;margin-bottom: 5px;"><strong><em>Journal Papers</em></strong></p> --><!-- + *[Learning Bayesian Network Structures Under Incremental Construction Curricula](http://dx.doi.org/10.1016/j.neucom.2017.01.092)*  **Yanpeng Zhao**, Yetian Chen, Kewei Tu, and Jin Tian.   Neurocomputing 2017. [[paper](http://dx.doi.org/10.1016/j.neucom.2017.01.092)]. --><!-- <p style="margin-top: 0;margin-bottom: 5px;"><strong><em>Conference Papers</em></strong></p> --><ul><li><a href="https://arxiv.org/pdf/1805.04688.pdf" target="_blank" rel="noopener">Gaussian Mixture Latent Vector Grammars</a><br><strong>Yanpeng Zhao</strong>, Liwen Zhang, Kewei Tu.<br>ACL 2018 (oral). [<a href="https://arxiv.org/pdf/1805.04688.pdf" target="_blank" rel="noopener">paper</a>], [<a href="https://github.com/zhaoyanpeng/lveg" target="_blank" rel="noopener">code</a>], [<a href="/files/acl2018_reviews.txt">reviews</a>].</li><li><a href="https://arxiv.org/pdf/1708.02071.pdf" target="_blank" rel="noopener">Structured Attentions for Visual Question Answering</a><br>Chen Zhu, <strong>Yanpeng Zhao</strong>, Shuaiyi Huang, Kewei Tu, and Yi Ma.<br>ICCV 2017 (poster). [<a href="https://arxiv.org/pdf/1708.02071.pdf" target="_blank" rel="noopener">paper</a>], [<a href="https://github.com/zhuchen03/vqa-sva" target="_blank" rel="noopener">code</a>], [<a href="/files/iccv2017_reviews.html">reviews</a>].</li><li><a href="http://dx.doi.org/10.1016/j.neucom.2017.01.092" target="_blank" rel="noopener">Learning Bayesian Network Structures Under Incremental Construction Curricula</a><br><strong>Yanpeng Zhao</strong>, Yetian Chen, Kewei Tu, and Jin Tian.<br>Neurocomputing 2017. [<a href="http://dx.doi.org/10.1016/j.neucom.2017.01.092" target="_blank" rel="noopener">paper</a>].</li><li><a href="http://proceedings.mlr.press/v57/zhao16.pdf" target="_blank" rel="noopener">Sequence Prediction Using Neural Network Classifiers</a><br><strong>Yanpeng Zhao</strong>, Shanbo Chu, Yang Zhou, and Kewei Tu.<br>ICGI 2016 (workshop track). [<a href="http://proceedings.mlr.press/v57/zhao16.pdf" target="_blank" rel="noopener">paper</a>], [<a href="http://spice.lif.univ-mrs.fr/slides/slides_tobewhat.pdf" target="_blank" rel="noopener">slides</a>].</li><li><a href="http://proceedings.mlr.press/v45/Zhao15a.pdf" target="_blank" rel="noopener">Curriculum Learning of Bayesian Network Structures</a><br><strong>Yanpeng Zhao</strong>, Yetian Chen, Kewei Tu, and Jin Tian.<br>ACML 2015 (oral). [<a href="http://proceedings.mlr.press/v45/Zhao15a.pdf" target="_blank" rel="noopener">paper</a>], [<a href="https://github.com/zhaoyanpeng/clbnsl" target="_blank" rel="noopener">code</a>], [<a href="http://sist.shanghaitech.edu.cn/faculty/tukw/acml15-poster.pdf" target="_blank" rel="noopener">poster</a>], [<a href="/files/acml2015_reviews.html">reviews</a>].</li><li><a href="https://arxiv.org/pdf/1808.04071.pdf" target="_blank" rel="noopener">Language Style Transfer from Non-Parallel Text with Arbitrary Styles</a><br><strong>Yanpeng Zhao</strong>, Victoria W. Bi, Deng Cai, Xiaojiang Liu, Kewei Tu, Shuming Shi.<br>Technical report, 2018. [<a href="https://arxiv.org/pdf/1808.04071.pdf" target="_blank" rel="noopener">paper</a>].</li></ul><!--## Experience+ [Tencent AI Lab](http://ai.tencent.com/ailab/index.html), Shenzhen, China, Jun 2017 - Oct 2017  Research Intern with Dr. Victoria W. Bi, Dr. Xiaojiang Liu, and Dr. Shuming Shi+ [SIST](http://sist.shanghaitech.edu.cn), ShanghaiTech University, Shanghai, China, Sep 2015 - Jun 2016  Teaching Assistant for CS100 (Programming Languages and Data Structures) and CS110 (Computer Architecture I)--><!--## Education+ *M.Sc., Computer Science.*&nbsp;Sep 2015 - Jun 2018  ShanghaiTech University, Shanghai, China  Thesis: Natural Language Parsing and Grammar Learning  Adviser: [Kewei Tu](http://sist.shanghaitech.edu.cn/faculty/tukw/)+ *B.E., Software Engineering.*&nbsp;Sep 2011 - Jun 2015  Wuhan University of Technology, Wuhan, China  Thesis: Curriculum Learning of Bayesian Network Structures--><!-- ## Selected Awards --><!-- + National Scholarships for Graduate Students (top 5%), 2017 --><!-- + Excellent Student, ShanghaiTech University (Awarded to top 15% students), 2016 --><!-- + 2nd place in the Sequence Prediction Challenge ([SPICE](http://spice.lif.univ-mrs.fr/)), ICGI 2016 --><!-- + Outstanding Graduate Award, Wuhan University of Technology, 2015 --><!-- + Outstanding Undergraduate Thesis Award, Hubei Province (top 5%), 2015 --><!-- + Meritorious Winner, The Mathematical Contest in Modeling (MCM) (top [11%](http://www2.cscamm.umd.edu/home/MCM2014.htm)), 2014 --><!-- + First prize for China Undergraduate Mathematical Contest in Modeling (CUMCM), Provincial Level, 2013 --><!-- + University Scholarships, Wuhan University of Technology, 2011-2014 --><!--## Professional Service+ Reviewer for the Neurocomputing Journal (2016, 2017)+ Volunteer at the ShanghaiTech Symposium on Information Science and Technology ([SSIST](http://ssist.shanghaitech.edu.cn/)), Jun 2016--><h2 id="Miscellaneous"><a href="#Miscellaneous" class="headerlink" title="Miscellaneous"></a>Miscellaneous</h2><ul><li>The avatar photo was taken during my road bike trip around the <a href="https://en.wikipedia.org/wiki/Qinghai_Lake" target="_blank" rel="noopener">Qinghai Lake</a> in the summer of 2012<!-- + Page style by courtesy of [xxx](#). --><!-- <table class="oops-table"><tbody> <tr> <td class="oops-left"><ul><li>M.Sc., Computer Science ShanghaiTech University, Shanghai, ChinaAdviser: Kewei Tu</li></ul></td> <td style="text-align:left;width:20%">Sep 2015 - Present</td> </tr><tr> <td class="oops-left">col 1 is</td> <td style="text-align:left">Sep 2011 - Jun 2015</td> </tr></tbody></table> --></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div style=&quot;display: flex;flex-wrap: wrap;font-family: &#39;Times New Roman&#39;;font-size: 14px;padding: 0;margin: -30px 0 30px 0&quot;&gt;&lt;div style=&quot;max-
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Bayesian Network Structure Learning Code and Data Library</title>
    <link href="http://zhaoyanpeng.cn/2015/08/14/Bayesian-Network-Structure-Learning-Code-And-Data-Library/"/>
    <id>http://zhaoyanpeng.cn/2015/08/14/Bayesian-Network-Structure-Learning-Code-And-Data-Library/</id>
    <published>2015-08-14T11:57:18.000Z</published>
    <updated>2017-07-31T07:53:04.000Z</updated>
    
    <content type="html"><![CDATA[<p>This page contains some software packages of PGM, which were found during my research on BNSL (Bayesian Network Structure Learning).</p><h1 id="BNSL-Source-Code-Library"><a href="#BNSL-Source-Code-Library" class="headerlink" title="BNSL Source Code Library"></a>BNSL Source Code Library</h1><h2 id="Weka"><a href="#Weka" class="headerlink" title="Weka"></a><a href="http://www.cs.waikato.ac.nz/ml/index.html" target="_blank" rel="noopener">Weka</a></h2><p><a href="http://weka.wikispaces.com/" target="_blank" rel="noopener">Weka Wiki</a>, Codes of BNSL in Weka lie in <code>weka.classifiers.bayes.net.search</code>. You can refer to <a href="">to be added</a> about the usage of Weka BNSL.</p><a id="more"></a><h2 id="BNT"><a href="#BNT" class="headerlink" title="BNT"></a><a href="https://github.com/bayesnet/bnt" target="_blank" rel="noopener">BNT</a></h2><p>Developed by <a href="http://www.cs.ubc.ca/~murphyk/" target="_blank" rel="noopener">Kevin Murphy</a>, Refer to <a href="http://www.cs.utah.edu/~tch/notes/matlab/bnt/docs/usage_02nov13.html" target="_blank" rel="noopener">How to use the Bayes Net Toolbox</a>, Codes of BNSL lie in <em>SLP</em>. By the way, <a href="http://ofrancois.tuxfamily.org/Docs/SLP_doc_1.5.pdf" target="_blank" rel="noopener">SLP</a> is separately developed based on BNT, and it has been already included in BNT. Another package developed based on BNT is <a href="http://www.sc.ehu.es/ccwbayes/members/rsantana/software/matlab/MATEDA.html" target="_blank" rel="noopener">Mateda2.0</a>. Kevin Murphy has also developed <a href="http://www.cs.ubc.ca/~murphyk/Software/BDAGL/" target="_blank" rel="noopener">BDAGL:Bayesian DAG learning</a>, but I never tried it.</p><h2 id="Causal-Explorer"><a href="#Causal-Explorer" class="headerlink" title="Causal Explorer"></a><a href="http://discover.mc.vanderbilt.edu/discover/public/" target="_blank" rel="noopener">Causal Explorer</a></h2><p>Source codes of the algorithm described in this paper are not provided (only <em>.p</em> files of the Matlab are available). My implementation of this algorithm in java can be accessed from <a href="https://github.com/zhaoyanpeng/clbnsl/tree/dev/src/main/java/edu/shanghaitech/ai/ml/clbnsl/bnsl/bayes/net/curricula" target="_blank" rel="noopener">MMPC</a>. Here is MMHC paper <a href="http://www.dsl-lab.org/supplements/mmhc_paper/mmhc_index.html" target="_blank" rel="noopener">home</a>.</p><h2 id="JavaBayes"><a href="#JavaBayes" class="headerlink" title="JavaBayes"></a><a href="http://www.cs.cmu.edu/~javabayes/Home/" target="_blank" rel="noopener">JavaBayes</a></h2><p>I tried it for interchanging file formats of BN. <a href="http://www.cs.cmu.edu/~fgcozman/Research/InterchangeFormat/" target="_blank" rel="noopener">The Interchange Format for Bayesian Networks</a> is to summarize and distribute information on an effort to standardize formats for representation of Bayesian networks and other related graphical models, but it seems to have stalled.</p><h2 id="BNJ"><a href="#BNJ" class="headerlink" title="BNJ"></a><a href="http://bnj.sourceforge.net/" target="_blank" rel="noopener">BNJ</a></h2><p>If you wanna get ideas of the implementation of <a href="http://arxiv.org/ftp/arxiv/papers/1301/1301.6696.pdf" target="_blank" rel="noopener">Sparse Candidate</a>, you can look through this one. But the documentation is not that good. E.g., <a href="http://sourceforge.net/projects/bndev/files/bndev/" target="_blank" rel="noopener">Dev Docs</a> doesn’t give the clear update infos.</p><h2 id="Banjo"><a href="#Banjo" class="headerlink" title="Banjo"></a><a href="http://www.cs.duke.edu/~amink/software/banjo/" target="_blank" rel="noopener">Banjo</a></h2><p>Simple and clear, could be used as the reference in developments.</p><h2 id="OpenMarkov"><a href="#OpenMarkov" class="headerlink" title="OpenMarkov"></a><a href="http://www.openmarkov.org/" target="_blank" rel="noopener">OpenMarkov</a></h2><p>The project is hosted on <a href="https://bitbucket.org/" target="_blank" rel="noopener">Bitbucket</a>.</p><h2 id="Tetrad"><a href="#Tetrad" class="headerlink" title="Tetrad"></a><a href="http://www.phil.cmu.edu/projects/tetrad/" target="_blank" rel="noopener">Tetrad</a></h2><p>Leaded by <a href="http://www.hss.cmu.edu/philosophy/faculty-spirtes.php" target="_blank" rel="noopener">Peter Spirtes</a>. Here is the induction from it’s home page</p><blockquote><p>…is to develop, analyze, implement, test and apply practical, provably correct computer programs for inferring causal structure under conditions where this is possible. </p></blockquote><h2 id="Elvira"><a href="#Elvira" class="headerlink" title="Elvira"></a><a href="http://leo.ugr.es/elvira/" target="_blank" rel="noopener">Elvira</a></h2><p>Some classical algorithms such as PC, K2 are included.</p><h2 id="PGM-Toolbox"><a href="#PGM-Toolbox" class="headerlink" title="PGM Toolbox"></a><a href="http://www.mensxmachina.org/software/pgm-toolbox/" target="_blank" rel="noopener">PGM Toolbox</a></h2><p>It perfectly explains OOP (Object Oriented Programming) in matlab.</p><h2 id="Infer-amp-URLearning-amp-WinMine"><a href="#Infer-amp-URLearning-amp-WinMine" class="headerlink" title="Infer &amp; URLearning &amp; WinMine"></a><a href="http://research.microsoft.com/en-us/um/cambridge/projects/infernet/default.aspx" target="_blank" rel="noopener">Infer</a> &amp; <a href="http://url.cs.qc.cuny.edu/resources.html" target="_blank" rel="noopener">URLearning</a> &amp; <a href="http://research.microsoft.com/en-us/um/people/dmax/WinMine/tooldoc.htm" target="_blank" rel="noopener">WinMine</a></h2><p>I have never tried them. Here are some other summaries of software packages of PGM: <a href="http://fuzzy.cs.uni-magdeburg.de/books/gm/tools.html" target="_blank" rel="noopener">Graphical Models Software Tools</a>, <a href="http://www.bayesnets.com/" target="_blank" rel="noopener">Bayes Nets</a>.</p><h1 id="Bayesian-Network-Repository"><a href="#Bayesian-Network-Repository" class="headerlink" title="Bayesian Network Repository"></a>Bayesian Network Repository</h1><p><a href="http://www.bnlearn.com/bnrepository/" target="_blank" rel="noopener">BNLearn</a> and <a href="http://www.cs.ubc.ca/~murphyk/Software/bnsoft.html" target="_blank" rel="noopener">Software Packages for Graphical Models</a> and <a href="http://www.cs.huji.ac.il/~galel/Repository/" target="_blank" rel="noopener">GalElidan</a>.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This page contains some software packages of PGM, which were found during my research on BNSL (Bayesian Network Structure Learning).&lt;/p&gt;
&lt;h1 id=&quot;BNSL-Source-Code-Library&quot;&gt;&lt;a href=&quot;#BNSL-Source-Code-Library&quot; class=&quot;headerlink&quot; title=&quot;BNSL Source Code Library&quot;&gt;&lt;/a&gt;BNSL Source Code Library&lt;/h1&gt;&lt;h2 id=&quot;Weka&quot;&gt;&lt;a href=&quot;#Weka&quot; class=&quot;headerlink&quot; title=&quot;Weka&quot;&gt;&lt;/a&gt;&lt;a href=&quot;http://www.cs.waikato.ac.nz/ml/index.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Weka&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;http://weka.wikispaces.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Weka Wiki&lt;/a&gt;, Codes of BNSL in Weka lie in &lt;code&gt;weka.classifiers.bayes.net.search&lt;/code&gt;. You can refer to &lt;a href=&quot;&quot;&gt;to be added&lt;/a&gt; about the usage of Weka BNSL.&lt;/p&gt;
    
    </summary>
    
      <category term="Manual" scheme="http://zhaoyanpeng.cn/categories/Manual/"/>
    
    
      <category term="Bayesian Network" scheme="http://zhaoyanpeng.cn/tags/Bayesian-Network/"/>
    
      <category term="Structure Learning" scheme="http://zhaoyanpeng.cn/tags/Structure-Learning/"/>
    
      <category term="Codes" scheme="http://zhaoyanpeng.cn/tags/Codes/"/>
    
  </entry>
  
  <entry>
    <title>Math Support for Hexo</title>
    <link href="http://zhaoyanpeng.cn/2015/04/11/Math-Support-for-Hexo/"/>
    <id>http://zhaoyanpeng.cn/2015/04/11/Math-Support-for-Hexo/</id>
    <published>2015-04-11T12:53:52.000Z</published>
    <updated>2017-06-21T11:47:10.000Z</updated>
    
    <content type="html"><![CDATA[<p><code>_</code> in Markdown conflicts with that in Latex, here is the solution to it:</p><blockquote><p>Hexo uses <a href="">Nunjucks</a> to render posts (<a href="">Swig</a> was used in older version, which share a similar syntax). Content wrapped with <code>{{  }}</code> or <code>{% %}</code>  will get parsed and may cause problems. You can wrap sensitive content with the raw tag plugin.</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;% raw %&#125;</span><br><span class="line">$$</span><br><span class="line">e^&#123;i \theta_&#123;t&#125;&#125; = \cos \theta_&#123;t&#125; + i \sin \theta_&#123;t&#125;</span><br><span class="line">$$</span><br><span class="line">&#123;% endraw %&#125;</span><br></pre></td></tr></table></figure><p>Results</p>$$e^{i \theta_{t}} = \cos \theta_{t} + i \sin \theta_{t}$$<p>Ref: <a href="https://hexo.io/docs/troubleshooting.html#Escape-Contents" target="_blank" rel="noopener">https://hexo.io/docs/troubleshooting.html#Escape-Contents</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;code&gt;_&lt;/code&gt; in Markdown conflicts with that in Latex, here is the solution to it:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Hexo uses &lt;a href=&quot;&quot;&gt;Nunjucks&lt;/a
      
    
    </summary>
    
      <category term="Manual" scheme="http://zhaoyanpeng.cn/categories/Manual/"/>
    
    
      <category term="mathjax" scheme="http://zhaoyanpeng.cn/tags/mathjax/"/>
    
      <category term="hexo" scheme="http://zhaoyanpeng.cn/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>A Beautiful Equation</title>
    <link href="http://zhaoyanpeng.cn/2015/04/04/A-Beautiful-Equation/"/>
    <id>http://zhaoyanpeng.cn/2015/04/04/A-Beautiful-Equation/</id>
    <published>2015-04-04T16:27:46.000Z</published>
    <updated>2017-06-21T11:45:40.000Z</updated>
    
    <content type="html"><![CDATA[<p>$${e \approx \left(1 + 9^{-4^{7 \times 6}}\right)^{3^{2^{85}}}}$$</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;$${e \approx \left(1 + 9^{-4^{7 \times 6}}\right)^{3^{2^{85}}}}$$&lt;/p&gt;

      
    
    </summary>
    
      <category term="Math" scheme="http://zhaoyanpeng.cn/categories/Math/"/>
    
    
      <category term="equation" scheme="http://zhaoyanpeng.cn/tags/equation/"/>
    
      <category term="exp" scheme="http://zhaoyanpeng.cn/tags/exp/"/>
    
  </entry>
  
</feed>
